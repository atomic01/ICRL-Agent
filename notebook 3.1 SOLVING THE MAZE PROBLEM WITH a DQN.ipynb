{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:27:26.155443Z",
     "start_time": "2020-10-05T19:27:24.797732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:27:26.785653Z",
     "start_time": "2020-10-05T19:27:26.156439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 10)           0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           110         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10)           0           add[0][0]                        \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 10)           0           add_1[0][0]                      \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           110         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 10)           0           add_2[0][0]                      \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           110         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 10)           0           add_3[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            44          add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 624\n",
      "Trainable params: 624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "skip = tf.keras.layers.Dense(10,activation='relu')(inputs)\n",
    "for i in range(5):\n",
    "    layer = tf.keras.layers.Dense(10,activation='relu')(skip)\n",
    "    skip = tf.keras.layers.Add()([skip,layer])\n",
    "outputs = tf.keras.layers.Dense(4,activation='linear')(skip)\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def loss_func(model,inputs,value):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs)\n",
    "        loss = tf.reduce_sum(tf.square(y_pred-value))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    return loss, grads\n",
    "\n",
    "opt = tf.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:27:26.789509Z",
     "start_time": "2020-10-05T19:27:26.787105Z"
    }
   },
   "outputs": [],
   "source": [
    "#actions: 0 = up, 1 = right, 2 = down, 3 = left\n",
    "actions = ['up', 'right', 'down', 'left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:27:53.811817Z",
     "start_time": "2020-10-05T19:27:53.781856Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "  if rewards[current_row_index, current_column_index] == -1.:\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "\n",
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "    state = np.array([[current_row_index, current_column_index]])\n",
    "    y_pred = model(state / (N-1))\n",
    "    buffer = y_pred.numpy()\n",
    "    \n",
    "    done = False\n",
    "    while done != True:\n",
    "        new_state = state.copy()\n",
    "        if np.random.uniform() > epsilon:\n",
    "            action = np.argmax(buffer)\n",
    "        else:\n",
    "            action = np.floor(np.random.uniform(0,4)).astype(np.int32)\n",
    "        new_row_index, new_column_index = get_next_location(state[0][0],state[0][1], action)\n",
    "        if not is_terminal_state(new_row_index, new_column_index):\n",
    "            done = True  \n",
    "        else:\n",
    "            buffer[0][action] = -100\n",
    "            \n",
    "    return action, y_pred\n",
    "\n",
    "\n",
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "  new_row_index = current_row_index\n",
    "  new_column_index = current_column_index\n",
    "  if actions[action_index] == 'up' and current_row_index > 0:\n",
    "    new_row_index -= 1\n",
    "  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
    "    new_column_index += 1\n",
    "  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
    "    new_row_index += 1\n",
    "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
    "    new_column_index -= 1\n",
    "  return new_row_index, new_column_index\n",
    "\n",
    "def get_shortest_path(start_row_index, start_column_index):\n",
    "  if is_terminal_state(start_row_index, start_column_index):\n",
    "    return []\n",
    "  else: \n",
    "    current_row_index, current_column_index = start_row_index, start_column_index\n",
    "    shortest_path = []\n",
    "    shortest_path.append([current_row_index, current_column_index])\n",
    "    while not is_terminal_state(current_row_index, current_column_index):\n",
    "      action_index,_ = get_next_action(current_row_index, current_column_index, 1)\n",
    "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
    "      shortest_path.append([current_row_index, current_column_index])\n",
    "      if len(shortest_path) > (environment_rows * environment_columns):\n",
    "        return shortest_path\n",
    "    return shortest_path\n",
    "\n",
    "\n",
    "def draw_shortest_path():\n",
    "    shortest_path = get_shortest_path(0, 3)\n",
    "    if shortest_path:\n",
    "        for i in shortest_path:\n",
    "            data[i[0], i[1]] = 0.4\n",
    "\n",
    "    plt.imshow(data, interpolation='nearest', cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:27:54.121317Z",
     "start_time": "2020-10-05T19:27:53.996584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100. -100. -100.   -1. -100. -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      "[-100.   -1. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
      "[-100.   -1.   -1.   -1. -100.   -1.   -1. -100.   -1. -100.]\n",
      "[-100.   -1. -100.   -1. -100.   -1. -100. -100.   -1. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1. -100.   -1.   -1. -100.]\n",
      "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100.]\n",
      "[-100.   -1. -100.   -1. -100.   -1. -100. -100.   -1. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
      "[-100. -100. -100. -100. -100. -100. -100.  100. -100. -100.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe18c01a290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment_rows = 10\n",
    "environment_columns = 10\n",
    "N = 10\n",
    "\n",
    "rewards = np.full((environment_rows, environment_columns), -100.)\n",
    "\n",
    "maze = {} \n",
    "maze[0] = [3]\n",
    "maze[1] = [i for i in range(1,9)]\n",
    "maze[2] = [1, 6, 8]\n",
    "maze[3] = [1, 2, 3, 5, 6, 8]\n",
    "maze[4] = [1, 3, 5, 8]\n",
    "maze[5] = [1, 2, 3, 4, 5, 7, 8]\n",
    "maze[6] = [5]\n",
    "maze[7] = [1, 3, 5, 8]\n",
    "maze[8] = [i for i in range(1,9)]\n",
    "\n",
    "for row_index in range(0,N-1):\n",
    "    for column_index in maze[row_index]:\n",
    "        rewards[row_index, column_index] = -1\n",
    "rewards[9, 7] = 100\n",
    "        \n",
    "for row in rewards:\n",
    "    print(row)\n",
    "    \n",
    "data = np.zeros((environment_columns, environment_rows))\n",
    "for j in range(environment_rows):\n",
    "    for i in range(environment_columns):\n",
    "        if rewards[j][i] == -100:\n",
    "            data[j][i] = 0\n",
    "        else:\n",
    "            data[j][i] = 1\n",
    "\n",
    "plt.imshow(data, interpolation='nearest', cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:32:23.852842Z",
     "start_time": "2020-10-05T19:28:47.871894Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 Rewards-- min:  -500.0  max:  -500.0  avg:  -50.0  loss:  tf.Tensor(0.01120471, shape=(), dtype=float32)\n",
      "Episode:  10 Rewards-- min:  -500.0  max:  -500.0  avg:  -500.0  loss:  tf.Tensor(5.160675e-06, shape=(), dtype=float32)\n",
      "Episode:  20 Rewards-- min:  -500.0  max:  -500.0  avg:  -500.0  loss:  tf.Tensor(0.00095442706, shape=(), dtype=float32)\n",
      "Episode:  30 Rewards-- min:  -500.0  max:  -500.0  avg:  -500.0  loss:  tf.Tensor(9.584366e-05, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1def6deb985a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_state\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#metrics variables-------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2248\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2252\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m    273\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0mchildren_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainable_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchildren_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_dedup_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   2958\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m     \u001b[0;34m\"\"\"Dedupe weights while maintaining order as much as possible.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2960\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentitySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2961\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/object_identity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define training parameters\n",
    "N = environment_rows\n",
    "discount_factor = 0.95\n",
    "number_of_episodes = 1000\n",
    "STEPS = 500\n",
    "sampling_frequency = 10\n",
    "epsilon = 0.99\n",
    "\n",
    "#image pixel data\n",
    "original_data = data.copy()\n",
    "data_array = np.zeros((environment_rows, environment_columns, int(number_of_episodes/sampling_frequency) ))\n",
    "\n",
    "#metrics sotrage arrays\n",
    "reward_array = []\n",
    "episode_array_for_minmaxavg = []\n",
    "min_reward_array = [] \n",
    "max_reward_array = []\n",
    "avg_reward_array = []\n",
    "number_of_steps_array = []\n",
    "loss_array = []\n",
    "V=[]\n",
    "for episode in range(number_of_episodes):\n",
    "    row_index = 0\n",
    "    column_index = 3 \n",
    "    \n",
    "    number_of_steps = 0\n",
    "    aggr_reward = 0    \n",
    "    while not is_terminal_state(row_index, column_index) and number_of_steps < STEPS:\n",
    "        action, y_pred = get_next_action(row_index, column_index, epsilon)\n",
    "        old_row_index, old_column_index, old_action, old_y_pred = row_index, column_index, action, y_pred\n",
    "        old_state = np.array([[old_row_index, old_column_index]])\n",
    "        row_index, column_index = get_next_location(old_row_index, old_column_index, action)\n",
    "        \n",
    "        state = np.array([[row_index, column_index]])\n",
    "        reward = rewards[row_index, column_index]\n",
    "        \n",
    "        y_pred = model(state/(N-1))\n",
    "        max_pred = np.max(y_pred,axis=1)\n",
    "        value = reward + discount_factor * max_pred\n",
    "        V.append(value.squeeze())\n",
    "        value = value - np.mean(V)\n",
    "        value = value / (np.std(V) + 0.0000001)\n",
    "        \n",
    "        y_target = old_y_pred.numpy().copy()\n",
    "        y_target[0][old_action] = value\n",
    "        \n",
    "        loss, grads = loss_func(model,old_state/(N-1),y_target)\n",
    "        opt.apply_gradients(zip(grads,model.trainable_variables))\n",
    "                                        \n",
    "        #metrics variables-------------------------------------------------------\n",
    "        aggr_reward +=reward  \n",
    "        number_of_steps += 1\n",
    "        #------------------------------------------------------------------------\n",
    "        \n",
    "    if epsilon > 0.05:\n",
    "        epsilon *= 0.999\n",
    "        \n",
    "    \n",
    "    reward_array.append(aggr_reward)    \n",
    "    number_of_steps_array.append(number_of_steps)\n",
    "    loss_array.append(loss)\n",
    "    \n",
    "    if episode%sampling_frequency ==  0:\n",
    "        index = int(episode / sampling_frequency)  \n",
    "        draw_shortest_path()\n",
    "        data_array[:,:,index] = data.copy()\n",
    "        data = original_data.copy()\n",
    "        \n",
    "        average_reward = sum(reward_array[-sampling_frequency:])/sampling_frequency\n",
    "        min_reward = min(reward_array[-sampling_frequency:])\n",
    "        max_reward = max(reward_array[-sampling_frequency:])       \n",
    "        print(\"Episode: \", episode,\"Rewards-- min: \", min_reward ,\" max: \", max_reward, \" avg: \", average_reward, \" loss: \", loss)\n",
    "\n",
    "        episode_array_for_minmaxavg.append(episode)\n",
    "        min_reward_array.append(min_reward)\n",
    "        max_reward_array.append(max_reward)\n",
    "        avg_reward_array.append(average_reward)\n",
    "    \n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:37:57.170944Z",
     "start_time": "2020-10-01T21:37:50.238681Z"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 30))\n",
    "columns = 10\n",
    "rows = int(number_of_episodes / columns / sampling_frequency)\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = data_array[:,:,i-1]\n",
    "    fig.add_subplot(rows, columns, i)    \n",
    "    plt.imshow(img, interpolation='nearest', cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:33:22.589503Z",
     "start_time": "2020-10-01T20:33:22.422823Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 10))\n",
    "plt.plot(reward_array,  label=\"Reward\" )\n",
    "plt.ylim(-200, 100)\n",
    "plt.title(\"Rewards per episode\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:33:22.747640Z",
     "start_time": "2020-10-01T20:33:22.590855Z"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 10))\n",
    "plt.plot(episode_array_for_minmaxavg, min_reward_array, label=\"Min\" )\n",
    "plt.plot(episode_array_for_minmaxavg, max_reward_array, label=\"Max\" )\n",
    "plt.plot(episode_array_for_minmaxavg, avg_reward_array, label=\"Avg\" )\n",
    "plt.title(\"Reward MIN MAX AVG per episode\")\n",
    "plt.ylim(-200, 100)\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:33:22.918848Z",
     "start_time": "2020-10-01T20:33:22.748617Z"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 10))\n",
    "plt.plot(number_of_steps_array,  label=\"Number of steps\" )\n",
    "plt.title(\"Number of steps per episode\")\n",
    "plt.ylim(-50, 100)\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:11:59.134020Z",
     "start_time": "2020-10-05T19:11:58.997980Z"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 10))\n",
    "plt.plot(loss_array,  label=\"Loss\" )\n",
    "plt.title(\"Loss per episode\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
