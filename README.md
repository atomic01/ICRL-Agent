# ğŸ¤– ICRL-Agent
*A Deep Reinforcement Learning Agent with Intermittent Control for Autonomous Driving*

---

## ğŸ§­ Overview
**ICRL-Agent** is a research project developed as part of my MSc thesis,  
**â€œDeep Learning Solutions for Autonomous Vehicles: Investigating the Impact of Intermittent Control on Reinforcement Learning.â€**

The project explores how **intermittent control theory**, inspired by human decision-making and motor control, can improve the **stability**, **efficiency**, and **robustness** of deep reinforcement learning (RL) agents operating in autonomous driving environments.

Two main environments were used for experimentation:
- **CARLA Simulator** â€” realistic autonomous vehicle training setup.  
- **Custom Maze Solver** â€” simplified RL environment for controlled algorithmic testing.

---

## ğŸ§± Repository Structure

| File | Description |
|------|--------------|
| `av_carla_icrl_agent.py` | Deep Q-Network (DQN) implementation with intermittent control for CARLA autonomous driving. |
| `av_carla_icrl_agent_demo.mp4` | Demonstration of the trained CARLA ICRL agent. |
| `maze_solver_icrl_agent.py` | Intermittent-control DQN applied to a 2D maze navigation task. |
| `maze_solver_dqn_agent.ipynb` | Baseline DQN maze-solving model (without intermittent control). |
| `maze_solver_qlearning_agent.ipynb` | Classical Q-Learning version for performance comparison. |

---

## âš™ï¸ Methodology
The research investigates how introducing **decision intervals** (intermittent control) affects RL agent behavior.

**Key Steps:**
1. Implemented **Deep Q-Networks (DQN)** with discrete control timing.  
2. Integrated **intermittent control logic** to simulate human-like reaction delays.  
3. Trained and compared **continuous vs. intermittent** control policies.  
4. Evaluated metrics focused on **training efficiency** rather than control accuracy,  
   including:
   - **Convergence speed** â€” time required to reach reward stabilization.  
   - **Sample efficiency** â€” number of episodes needed for consistent performance.  
   - **Computation cost** â€” training time per episode and overall runtime.  
   - **Stability under intermittent updates** â€” observing variance in learning curves.  

---

## ğŸ§ª Notes
The experiments demonstrated that intermittent control can reduce the overall training
time required for convergence while maintaining comparable reward performance to
continuously controlled agents â€” suggesting a potential improvement in computational
efficiency for resource-constrained RL systems.

- Designed for **academic research** and proof-of-concept evaluation.  
- Code focuses on demonstrating behavior differences, not production optimization.  
- Results may vary depending on **TensorFlow/PyTorch** and **CARLA** versions.  

---

## ğŸ§° Technologies Used
Python â€¢ TensorFlow â€¢ NumPy â€¢ OpenAI Gym â€¢ CARLA Simulator â€¢ Jupyter  

---

## ğŸ“ Academic Context
This repository supports my MSc thesis submitted to  
**Manchester Metropolitan University (2020)**.  

The research investigates how integrating intermittent control theory into RL can enhance decision-making reliability and performance for autonomous vehicles.

---

## ğŸ¥ Demo
<p align="center">
  <a href="av_carla_icrl_agent_demo.mp4">â–¶ï¸ Watch CARLA Driving Demo</a>
</p>
